{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs8KQ8xb4HYN"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers opencv-python pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "jGb1BWSuP61i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow # Import cv2_imshow from google.colab.patches\n",
        "\n",
        "# Load YOLOv8 model using torch\n",
        "model=YOLO('/content/best.pt')\n",
        "\n",
        "# Load TrOCR model and processor for OCR\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "ocr_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "\n",
        "video_file = \"/content/output_video.mp4\"  # Path to your video file\n",
        "output_file = \"/content/results.txt\"\n",
        "\n",
        "# Preprocess image for OCR model (convert OpenCV image to PIL)\n",
        "def preprocess_for_ocr(plate_img):\n",
        "    # Convert OpenCV Mat (BGR) to RGB format and then to PIL image\n",
        "    pil_img = PILImage.fromarray(cv2.cvtColor(plate_img, cv2.COLOR_BGR2RGB))\n",
        "    return pil_img\n",
        "\n",
        "# Decode the OCR predictions\n",
        "def decode_predictions(ocr_inputs):\n",
        "    pixel_values = processor(images=ocr_inputs, return_tensors=\"pt\").pixel_values\n",
        "    generated_ids = ocr_model.generate(pixel_values)\n",
        "    plate_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return plate_text.strip()\n",
        "\n",
        "cap = cv2.VideoCapture(video_file)\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "    exit()\n",
        "\n",
        "frame_number = 0\n",
        "with open(output_file, 'w') as writer:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_number += 1\n",
        "\n",
        "        # Convert frame to RGB and resize to 640x640 for YOLO model\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = model(frame_rgb)\n",
        "\n",
        "        # Get detected bounding boxes\n",
        "        boxes = results[0].boxes  # Extract the boxes object\n",
        "        for box in boxes:\n",
        "            # Extract coordinates and confidence from the box\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            conf = box.conf.item()\n",
        "            class_id = box.cls.item()\n",
        "\n",
        "            # Crop the detected license plate region\n",
        "            plate_img = frame[y1:y2, x1:x2]\n",
        "\n",
        "            # Preprocess the plate image for the OCR model\n",
        "            preprocessed_plate = preprocess_for_ocr(plate_img)\n",
        "\n",
        "            # Perform OCR using the TrOCR model\n",
        "            plate_text = decode_predictions(preprocessed_plate)\n",
        "\n",
        "            # Write the result to the output file\n",
        "            writer.write(f\"Frame {frame_number}: Detected plate - {plate_text}\\n\")\n",
        "\n",
        "            # Draw the bounding box and detected text on the frame\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        # Display the frame with the detected bounding boxes\n",
        "        cv2_imshow(frame) # Use cv2_imshow instead of cv2.imshow\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "k290qoSIec8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}